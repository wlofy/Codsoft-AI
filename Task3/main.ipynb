{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding\n",
    "\n",
    "image_model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "def load_image(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "    x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "    return image_model.predict(x).reshape(-1)\n",
    "\n",
    "max_length = 20\n",
    "vocab_size = 10000\n",
    "embedding_dim = 256\n",
    "\n",
    "inputs1 = Input(shape=(4096,))\n",
    "fe1 = Dense(256, activation='relu')(inputs1)\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "se1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "se2 = LSTM(256)(se1)\n",
    "\n",
    "decoder1 = tf.keras.layers.add([fe1, se2])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "caption_model = Model(inputs=[inputs1, inputs2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [...]\n",
    "captions = [...]\n",
    "\n",
    "image_features = [load_image(image_path) for image_path in images]\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(captions)\n",
    "sequences = tokenizer.texts_to_sequences(captions)\n",
    "\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "train_images, val_images, train_sequences, val_sequences = train_test_split(image_features, padded_sequences, test_size=0.2)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "history = caption_model.fit([train_images, train_sequences], np.array(train_sequences), \n",
    "                            batch_size=batch_size, epochs=epochs, \n",
    "                            validation_data=([val_images, val_sequences], np.array(val_sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image_path):\n",
    "    image_features = load_image(image_path)\n",
    "    in_text = '<start>' \n",
    "    for i in range(max_length):\n",
    "        sequence = [word_to_index[w] for w in in_text.split() if w in word_to_index]\n",
    "        sequence = tf.keras.preprocessing.sequence.pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = caption_model.predict([image_features, sequence], verbose=0)\n",
    "        yhat = tf.argmax(yhat)\n",
    "        word = index_to_word[yhat.numpy()]\n",
    "        in_text += ' ' + word\n",
    "        if word == '<end>':\n",
    "            break\n",
    "    final = in_text.split()[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
